---
layout: post
title:  Generating different patterns using kernel functions 
project timeline: Sept'21-Mar'22
# description: The goal of the project is to enable faster and more precise eye gaze direction estimation in VR/AR/MR devices by exploiting the deflectometry information provided from the reflection of the screen pattern on the specular surface of the eye 
img: att.png # Add image post (optional)
tags: [ Kernel,activation map ] # add tag
---

## Motivation 
As mentioned in my post on "Deep Learning-Based Eye Gaze Estimation using Deflectometry Information in VR/AR/MR Headsets" we utilize learning-based and inverse rendering-based approaches to more accurately infer the eye gaze direction from the deformation of the reflected pattern on the eye surface.

## Pattern selection 
We started with low frequency patterns and used a homogenous white image. We varied the patterns to test the hypothesis that whether the 
accuracy increases for the high frequency patterns as opposed to the low frequency patterns(For the high frequency pattern, we use a sinusoidal pattern).

To improve performance, I generated more varied patterns. One of the method that I used to generate patterns was using kernel functions. The advantage was that I could produce many different patterns simply by changing few parameters.

## Kernel
A kernel is essentially a fixed size array of numerical coefficients along with an anchor point in that array, which is typically located at the center.
In order to be a valid kernel function the resulting kernel matrix should be positive definite which implies that the matrix should be symmetric.
Being positive definite also means that the kernel matrix is invertible .


### Exponentiated quadratic kernel
![eq1](../assets/img/eq1.png){: width="900" }

Using the exponentiated quadratic kernel will result in a smooth prior on functions sampled from the Gaussian process.


The following figure shows samples from the exponentiated quadratic kernel together with a visual representation of its covariance matrix.

![f1](../assets/img/f1.png){: width="300" }

### Rational quadratic kernel
![eq2](../assets/img/eq2.png){: width="900" }

Similar to the exponentiated quadratic the rational quadratic kernel will result in a somewhat smooth prior on functions sampled from the Gaussian process. The rational quadratic can be interpreted as an infinite sum of different exponentiated quadratic kernels with different lengthscales 

The following figure shows samples from the rational quadratic kernel together with a visual representation of its covariance matrix. The amplitude  is fixed to  in all figures, changing the amplitude will have the same effect as changing the amplitude in the exponentiated quadratic.

![f2](../assets/img/f2.png){: width="300" }


### Periodic kernel
![eq3](../assets/img/eq3.png){: width="900" }

The periodic kernel allows us to model periodic functions .

The following figure shows samples from the periodic kernel together with a visual representation of its covariance matrix.

![f3](../assets/img/f3.png){: width="300" }


### Local periodic kernel
Kernels can be combined by multiplying them together. Multiplying kernels is an elementwise multiplication of their corresponding covariance matrices. This means that the covariances of the two multiplied kernels will only have a high value if both covariances have a high value. The multiply operation can thus be interpreted as an AND operation.


![eq4](../assets/img/eq3.png){: width="900" }


The local periodic kernel is a multiplication of the periodic kernel with the exponentiated quadratic kernel to allow the periods to vary over longer distances. Note that the variance parameters are combined into one.

![f4](../assets/img/f4.png){: width="300" }


## Heat Map and activation Map for analysis 
To evaluate the patterns, I first reflected all the patterns on the eye model using blender. I used activation map to understand which part of the image(reflected pattern on the eye surface) contributes more in providing the resulting value of gaze direction.(caclulation of gaze directions is mentioned in "Deep Learning-Based Eye Gaze Estimation using Deflectometry Information in VR/AR/MR Headsets" post).

![a1](../assets/img/activ1.png){: width="200" }
![a2](../assets/img/act3.png){: width="300" }
![a3](../assets/img/act2.png){: width="350" }


The activation map test was performed on all the pattern with each pattern being trained on dataset with 10800 images. The experiment showed that in order to improve the gazing direction we need to consider the undersampling situation happening at the boundary of the cornea and sclera because of the abrupt change in curvature.This helped us to draw conclusion that "effect of aliasing" hurts the accuracy of the gaze direction.


[CODE](https://github.com/ashleetiw/pattern-generation)

## References
1:[https://www.cs.toronto.edu/~duvenaud/cookbook/](https://www.cs.toronto.edu/~duvenaud/cookbook/)
2:[http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf](http://cnnlocalization.csail.mit.edu/Zhou_Learning_Deep_Features_CVPR_2016_paper.pdf)
3:[https://peterroelants.github.io/posts/gaussian-process-kernels/#Kernel-function](https://peterroelants.github.io/posts/gaussian-process-kernels/#Kernel-function)


