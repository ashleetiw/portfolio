I"–<p>The goal of the project is to enable faster and more precise eye gaze direction estimation in VR/AR/MR devices by exploiting the deflectometry information provided from the reflection of the screen pattern on the specular surface of the eye.</p>

<p>This is my final graduate project at Northwestern University. I was supervised by</p>
<ol>
  <li>Professor Florian Willomitzer, and Oliver Cossairt, ECE/CS Department</li>
  <li>Nathan Matsuda, Ph.D., Facebook Reality Labs</li>
  <li>Professor Matthew Elwin, Deputy Director of the Master of Robotics Program</li>
</ol>

<blockquote>
  <p>This project is current work in progress. More information will be available soon.</p>
</blockquote>

<h2 id="motivation">Motivation</h2>
<p>The project aims to solve one of the current problems in Virtual, Augmented, or Mixed Reality
Headsets: Accurate and fast eye tracking. Precise eye tracking in VR/AR/MR Headsets can help to significantly increase the viewing comfort by continuously keeping track of the inter-pupillary distance (IPD) of the viewer. This is important since changing the eye‚Äôs focus (accommodation) is in natural scenes directly connected to the vergence of the optical axes of both eyes(‚Äúaccommodation-convergence reflex‚Äù).</p>

<h2 id="problem-statement">Problem Statement:</h2>
<p>High-quality gaze tracking requires sufficient 3D scene understanding since the vertex of the eye must be precisely tracked
in three dimensions.This requires a precise and dense single-shot 3D measurement of the eye surface and a procedure to evaluate
these measurement to calculate the gazing direction.</p>

<h2 id="the-principle-of-the-normal-measurement-in-deflectometry">The principle of the normal measurement in deflectometry</h2>
<p>The purpose of this project is to significantly increase the information content that is provided by corneal or scleral reflection to calculate the gazing direction.</p>

<p><img src="../assets/img/deflectometry.jpg" alt="approach" width="600" />
<em>Deflectometry[1]</em></p>

<p>The basic principle of Deflectometry: A screen that displays a known pattern replaces the point-like light source.
In Deflectometry systems, the screen and camera face the object, which means that the camera observes the specular reflection of the screen over
the object‚Äôs surface. The observed pattern in the camera image is a deformed version of the image on the screen,
where the deformation depends on the surface normal distribution of the object surface. From this deformation,
the normal vectors of the surface can be calculated.</p>

<h2 id="calculation-of-the-gazing-direction-by-tracing-back-the-measured-surface-normals-to-the-scleral-and-corneal-center">Calculation of the gazing direction by tracing back the measured surface normals to the scleral and corneal center.</h2>

<p><img src="../assets/img/cacl_gaze.png" alt="gaze" width="600" />
<em>VR Eye Tracking using Deflectometry[2]</em></p>

<h2 id="model-design-swirski-eye">Model Design: Swirski Eye</h2>
<p>It is very crucial to have a model that captures realistic face geometry, including eyelids and eyebrows, that animates in response to the eye movements and different closeness settings. To create a realistic render of the eye,we used Swirski model with an eyeball with the elevated cornea.To load and animate the model we used Blender, which is a free and open-source 3D computer graphics software.</p>

<p><img src="../assets/img/eyemodel.gif" alt="eye" width="600" /></p>

<!-- ## Single Frame Deflectometry Network(SFDN) vs Double Frame Deflectometry (DFDN)
The project initially used SFDN which takes a single eye image as an input and predicts two rotation angles of the eye: azimuth and elevation
Drawback: SFDN can only work well with a fixed pattern that it was trained with.

To overcome this issue, I chose Double Frame Deflectometry Network(DFDN), to allow arbitrary screen patterns for the inputs


DFDN takes a pair of eye images, where one is an actual captured image and the other
is a synthesized eye image with preset rotation angles and the reflection of an arbitrary pattern(reference image)

A reference image plays a role in providing the network
with some information about the arbitrary pattern that is being reflected on the captured eye image. -->

<!-- 
## Architecture of the Double Frame Deflectometry Network

Goal: To learn the relationship between the screen pattern of a captured image and that of a reference image to estimate the gaze direction based on the deformation of the pattern due to the rotation of the eye.

![model](../assets/img/model.png){: width="600" }

I chose Double Frame Deflectometry Network(DFDN), to allow arbitrary screen patterns for the inputs. DFDN takes a pair of eye images, where one is an actual captured imag and the other is a synthesized eye image with preset rotation angles and the reflection of an arbitrary pattern(reference image). A reference image plays a role in providing the network with some information about the arbitrary pattern that is being reflected on the captured eye image.
 -->
<!-- 
## Investigation of effects of various patterns on gaze estimation accuracy


### Random pattern with various low pass filters
![g](../assets/img/gaussian.png){: width="600" }


### Sinusoids of different periods
![sine](../assets/img/sine.png){: width="600" }

 -->

<h2 id="effect-of-aliasing">Effect of Aliasing</h2>
<p>A severe undersampling happens at the boundary of the cornea and sclera because of the abrupt change in curvature.To capture details correctly, we need to find the optimal
the pattern.</p>

<p><img src="../assets/img/alias_70.png" alt="alias" width="400" /></p>

<h2 id="pattern-optimization">Pattern optimization</h2>
<p>From various experiments we concluded the following:</p>
<ol>
  <li>The true relationship between the frequency of the pattern and the estimation accuracy may be nonlinear. There may be a sweet spot, or the ideal frequency, where the network can minimize the estimation error. (This is due to the presence of a sharp edge between cornea and sclera)</li>
  <li>The frequency might not be the exact property that is associated with accuracy.</li>
</ol>

<p>We test various hypothesis on the properties of patterns that may affect the accuracy, and in the process we aim to find the optimal
the pattern that yields the lowest error.
In this process I focused on using algorithms to find the optimal pattern in two steps:</p>
<ol>
  <li>To perform a course-level optimization to determine the shape of the function. This was achieved by using the genetic algorithm (which is mentioned in a different post) which eliminated some of the functions from the pool of hypothetical functions formed using a fitness function.</li>
  <li>To perform a fine-level optimization to fine-tune the constants. This was achieved by gradient descent optimization on L2 loss which was calculated on gazing direction values(azimuthal and elevation angle).</li>
</ol>

<h2 id="radial-convolution">Radial convolution</h2>
<p>Different filters are applied to different pixels based on the radial distance from the center. Convolution was implemented from scratch because all the library based convolution method is based on FFT which applies the kenel to the entire image uniformly.</p>

<p><img src="../assets/img/final.gif" alt="approach" width="600" />
<img src="../assets/img/my-eye.png" alt="my-eye" width="190" /></p>

<p><a href="https://github.com/ashleetiw/non-uniform-lowpass-filter">NON-UNIFORM KERNEL CODE</a></p>

<h2 id="references">References</h2>
<p>1:<a href="https://www.sciencedirect.com/science/article/abs/pii/S0143816618300599">https://www.sciencedirect.com/science/article/abs/pii/S0143816618300599</a>
2:<a href="https://3dim.northwestern.edu/JWang_COSI_2021.pdf">https://3dim.northwestern.edu/JWang_COSI_2021.pdf</a>
3:<a href="https://opg.optica.org/DirectPDFAccess/816F2BF0-49F5-4B5F-BCDD95E403FEF3A5_429104/oe-28-7-9027.pdf?da=1&amp;id=429104&amp;seq=0&amp;mobile=no">https://opg.optica.org/DirectPDFAccess/816F2BF0-49F5-4B5F-BCDD95E403FEF3A5_429104/oe-28-7-9027.pdf?da=1&amp;id=429104&amp;seq=0&amp;mobile=no</a></p>

:ET